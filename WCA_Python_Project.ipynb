{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9fed88-3962-4180-b08f-8b6baa9386c2",
   "metadata": {},
   "source": [
    "# Analyzing 3x3 Data From WCA Competitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c1bcf3-dbe5-4eff-bc98-4d0c894fbacf",
   "metadata": {},
   "source": [
    "In this project I use python to analyze data on Rubik's Cube competitions hosted by the WCA, or \"World Cube Association.\" \n",
    "Many different events are held besides the traditional 3x3 cube, although I will focus solely on 3x3 for this analysis. There are a total of 17 events, including 3x3 blindfolded and 7x7. The competitions are structured in the following manner: There are a certain number of rounds for each event, typically 2-4 rounds. In each round, competitors will generally do 5 solves. The worst and best time are thrown out and the middle 3 are averaged. This determines the ranking for the competitors in each round. Less competitors advanced after each round, with the final round typically being 12-16 competitors. The person with the fastest average time in the final round wins the event for that competition. For more information on the WCA and WCA competitions, visit the WCA website [here](https://www.worldcubeassociation.org/). The dataset can be exported from [here](https://www.worldcubeassociation.org/export/results)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa55166-b545-40a9-9e9b-1b68b03b7e77",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7b469f-267a-4d8c-b5c2-e883f5e61601",
   "metadata": {},
   "source": [
    "First we will import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a6f7a1b-40ae-417e-b0f2-098ce9cff42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae424b20-1525-4a01-b262-dd1e86fadcf7",
   "metadata": {},
   "source": [
    "Next, I need to read the data into pandas dataframes. The data was exported from the WCA website in tsv format. The necessary data is contained within 3 seperate tsv files we need to read. Firstly, there is the \"results\" file. This file shows information on individual averages done in WCA competitions. Secondly, there is the \"persons\" file, which shows information on every WCA competitor. We will use this file only to get the gender of each competitor. Finally, there is the \"competitions\" file, which contains information on individual WCA competitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35baf77f-eb11-4a90-90bc-714a1ddedf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  competitionId eventId roundTypeId               personName    personId  \\\n",
      "0  LyonOpen2007     333           1            Etienne Amany  2007AMAN01   \n",
      "1  LyonOpen2007     333           1           Thomas Rouault  2004ROUA01   \n",
      "2  LyonOpen2007     333           1  Antoine Simon-Chautemps  2005SIMO01   \n",
      "3  LyonOpen2007     333           1           Irène Mallordy  2007MALL01   \n",
      "4  LyonOpen2007     333           1       Marlène Desmaisons  2007DESM01   \n",
      "\n",
      "   value1  value2  value3  value4  value5 personCountryId  \n",
      "0    1968    2203    2138    2139    2108   Cote d_Ivoire  \n",
      "1    2222    2153    1731    2334    2046          France  \n",
      "2    3430    2581    2540    2789    2305          France  \n",
      "3    2715    2452    2868    2632    2564          France  \n",
      "4    2921    3184    2891    2677    2907          France  \n"
     ]
    }
   ],
   "source": [
    "results = pd.read_csv(r'Data/WCA_export_Results.tsv', sep='\\t', usecols=[\"competitionId\", \"eventId\", \"roundTypeId\", \"personName\", \"personId\", \"value1\", \"value2\", \"value3\", \"value4\", \"value5\", \"personCountryId\"])\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44fa8703-2964-4082-8805-99dca2a66c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  gender          id\n",
      "0      m  1982BORS01\n",
      "1      m  1982BRIN01\n",
      "2      m  1982CHIL01\n",
      "3      f  1982FRID01\n",
      "4      f  1982FRID01\n"
     ]
    }
   ],
   "source": [
    "persons = pd.read_csv(r\"Data/WCA_export_Persons.tsv\", sep=\"\\t\", usecols=[\"id\", \"gender\"])\n",
    "print(persons.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cacec5e-d8aa-4155-8f0e-dc3cf96c5781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             id  countryId  year  month  day\n",
      "0                 100Merito2018     Brazil  2018      4   14\n",
      "1    100YearsRepublicAnkara2023     Turkey  2023     10   28\n",
      "2  100YearsRepublicIstanbul2023     Turkey  2023     10   28\n",
      "3      100YilMBACubeWeekend2023     Turkey  2023     12   16\n",
      "4    10AniversarioGuatemala2023  Guatemala  2023     10   14\n"
     ]
    }
   ],
   "source": [
    "competitions = pd.read_csv(r\"Data/WCA_export_Competitions.tsv\", sep=\"\\t\", usecols=[\"id\", \"countryId\", \"year\", \"month\", \"day\"])\n",
    "print(competitions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99caf73c-bb9b-43ef-bac1-bea44d63fb69",
   "metadata": {},
   "source": [
    "## Data Cleaning and Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743386c-bbcc-423c-a6c0-3248d01f7008",
   "metadata": {},
   "source": [
    "I need to adjust the results dataframe a bit, making a couple of changes. First, we only want to include averages where all 5 solves were completed. This is due to some later analysis we will do on median solve time for different solve numbers. Often times time limits will be imposed in competitions, and these time limits must be met within the first 2 solves. If we include the results for any solve done, then the first 2 solves will have a higher median time due to slow competitors only being allowed to complete the first 2 solves. I also change the dataframe so that every row is one solve. Additionally, I make the \"variable\" column which shows what solve number the solve was just a numeric column by removing the \"value\" part. I then filter for only 3x3 solves and divide the times by 100 so they will be shown in seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b5ddf7b-ee9c-46fe-9ead-f1db686b6bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  competitionId eventId               personName    personId personCountryId  \\\n",
      "0  LyonOpen2007     333            Etienne Amany  2007AMAN01   Cote d_Ivoire   \n",
      "1  LyonOpen2007     333           Thomas Rouault  2004ROUA01          France   \n",
      "2  LyonOpen2007     333  Antoine Simon-Chautemps  2005SIMO01          France   \n",
      "3  LyonOpen2007     333           Irène Mallordy  2007MALL01          France   \n",
      "4  LyonOpen2007     333       Marlène Desmaisons  2007DESM01          France   \n",
      "\n",
      "  roundTypeId variable  value  \n",
      "0           1        1  19.68  \n",
      "1           1        1  22.22  \n",
      "2           1        1  34.30  \n",
      "3           1        1  27.15  \n",
      "4           1        1  29.21  \n"
     ]
    }
   ],
   "source": [
    "results = results[(results[\"value1\"] > 0) & (results[\"value2\"] > 0) & (results[\"value3\"] > 0) & (results[\"value4\"] > 0) & (results[\"value5\"] > 0)]\n",
    "results = results.melt(id_vars=[\"competitionId\", \"eventId\", \"personName\", \"personId\", \"personCountryId\", \"roundTypeId\"], value_vars=[\"value1\", \"value2\", \"value3\", \"value4\", \"value5\"])\n",
    "results[\"variable\"] = results[\"variable\"].str.replace(\"value\", \"\")\n",
    "results = results[results[\"eventId\"] == \"333\"]\n",
    "results[\"value\"] = results[\"value\"]/100\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e1491c-8ef9-4500-ada2-8ec0b6e79b1e",
   "metadata": {},
   "source": [
    "Next, I need to adjust the \"competitions\" dataframe so that there is one single datetime column showing the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cf8928a-499a-461e-a005-bd419d621cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             id  countryId       date\n",
      "0                 100Merito2018     Brazil 2018-04-14\n",
      "1    100YearsRepublicAnkara2023     Turkey 2023-10-28\n",
      "2  100YearsRepublicIstanbul2023     Turkey 2023-10-28\n",
      "3      100YilMBACubeWeekend2023     Turkey 2023-12-16\n",
      "4    10AniversarioGuatemala2023  Guatemala 2023-10-14\n"
     ]
    }
   ],
   "source": [
    "competitions[\"date\"] = pd.to_datetime(competitions[[\"day\", \"month\", \"year\"]])\n",
    "competitions = competitions.drop(columns=[\"day\", \"month\", \"year\"])\n",
    "print(competitions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ef306b-2085-4fc5-b16e-356abe719f22",
   "metadata": {},
   "source": [
    "Finally, I need to merge the datasets together into one dataframe. I also rename a few of the columns to be more meaningful and reorder them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1a2151f-a474-41fc-9602-88ddc0ffb5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     personId               personName personCountryId gender   time  \\\n",
      "0  2007AMAN01            Etienne Amany   Cote d_Ivoire      m  19.68   \n",
      "1  2004ROUA01           Thomas Rouault          France      m  22.22   \n",
      "2  2005SIMO01  Antoine Simon-Chautemps          France      m  34.30   \n",
      "3  2007MALL01           Irène Mallordy          France      f  27.15   \n",
      "4  2007DESM01       Marlène Desmaisons          France      f  29.21   \n",
      "\n",
      "  solveNumber roundTypeId       date competitionCountryId  \n",
      "0           1           1 2007-09-01               France  \n",
      "1           1           1 2007-09-01               France  \n",
      "2           1           1 2007-09-01               France  \n",
      "3           1           1 2007-09-01               France  \n",
      "4           1           1 2007-09-01               France  \n"
     ]
    }
   ],
   "source": [
    "data = results.merge(persons, left_on = \"personId\", right_on = \"id\")\n",
    "data = data.merge(competitions, left_on = \"competitionId\", right_on = \"id\")\n",
    "data = data.drop(columns=[\"id_x\", \"id_y\", \"competitionId\", \"eventId\"])\n",
    "data = data.rename(columns={\"variable\": \"solveNumber\", \"value\": \"time\", \"countryId\": \"competitionCountryId\"})\n",
    "data = data.reindex(columns = [\"personId\", \"personName\", \"personCountryId\", \"gender\", \"time\", \"solveNumber\", \"roundTypeId\", \"date\", \"competitionCountryId\"])\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac933aa1-f6cf-43cc-9622-dbdc7fa8c5da",
   "metadata": {},
   "source": [
    "## Analyzing Solve Speed by Solve Number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9cd5bf-65b6-4a4d-9217-cd22e8c8ba39",
   "metadata": {},
   "source": [
    "We will simply examine the median solve time by solve number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5a13d26-7754-4f09-afca-127539c27f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             median    count\n",
      "solveNumber                 \n",
      "1             15.94  1353509\n",
      "2             15.93  1353509\n",
      "3             15.90  1353509\n",
      "4             15.88  1353509\n",
      "5             15.87  1353509\n"
     ]
    }
   ],
   "source": [
    "by_number = data[\"time\"].groupby(data[\"solveNumber\"]).agg([\"median\", \"count\"])\n",
    "print(by_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b3e391-de31-413f-945a-e42976fbd466",
   "metadata": {},
   "source": [
    "We can see there seems to be a steady improvement in solve speed over time, with later solves being faster than earlier solves. This is the result I would expect. At the beginning of the average, competitors might be nervous, needing time to adjust to the competition atmosphere. As the average goes on they get used to the situation and become faster. However, I suspect this is not always the case, particularly if the first few solves went very well, they might start to get nervous and perform poorly, knowing a very fast average is possible if they continue getting good results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1079bdd-3509-4009-9298-e1f347589bca",
   "metadata": {},
   "source": [
    "## Analyzing Solve Speed of New Competitors Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef2e613-960d-48b8-bf77-3273eedbbd71",
   "metadata": {},
   "source": [
    "I'm also interested in how fast new competitors have gotten over time. This could show us how Rubik's Cube hardware and solving techniques have advanced over time. We can find out what year a competitor started in by looking at the \"personId\" column, as the number at the start of the values contains this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e0926ee1-f4cf-4770-abe0-3f47901d75d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      median   count\n",
      "date                \n",
      "2003  21.420      35\n",
      "2004  31.345     560\n",
      "2005  31.480    1745\n",
      "2006  29.650    2970\n",
      "2007  32.580    6225\n",
      "2008  28.980   12660\n",
      "2009  28.900   23605\n",
      "2010  26.650   27895\n",
      "2011  25.710   30090\n",
      "2012  26.640   29570\n",
      "2013  27.190   44130\n",
      "2014  28.030   66645\n",
      "2015  27.680   87470\n",
      "2016  26.560  130550\n",
      "2017  24.930  180200\n",
      "2018  26.600  194495\n",
      "2019  26.370  209345\n",
      "2020  29.600   24515\n",
      "2021  22.760   30200\n",
      "2022  22.840  251725\n",
      "2023  24.700  372395\n",
      "2024  26.140  299675\n",
      "2025  30.060   44750\n"
     ]
    }
   ],
   "source": [
    "same_year = data[data[\"personId\"].str[:4] == data[\"date\"].dt.year.astype(str)]\n",
    "same_year_medians = same_year[\"time\"].groupby(same_year[\"date\"].dt.year).agg([\"median\", \"count\"])\n",
    "print(same_year_medians)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346fc601-1bef-4670-b2c0-226d2255688b",
   "metadata": {},
   "source": [
    "I find the data to be quite surprising. It doesn't seem like there is much of an improvement over time. For example, the median solve time in 2011 was faster than in 2024. I think one possible explanation could be due to more widespread competitions. Over time the amount of competitions taking place has increased drastically, which makes it easier for now competitors to compete right away. If we go back many years, people might have waited a lot longer to go to their first competition due to the lack of availability, causing them to have faster times initially due to having more experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6856322b-4f22-4023-8f8b-b9c830737818",
   "metadata": {},
   "source": [
    "## Analyzing the Rise of Top Chinese Speedcubers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db58b21-7921-4c11-a68e-429130c7d87c",
   "metadata": {},
   "source": [
    "An interesting phenomenon his arise among top competitors: many of them are now from China. I examine this situation and see if I can explain it. First, we can see if China accounts for a larger percentage of overall competitors than before. If China accounts for a larger percent of all competitors it would make sense that they would also account for a larger percent of top competitors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a3d36914-29e9-4438-88d6-aadcdf1568f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TotalCompetitors  ChinaCount  ChinaPercent\n",
      "year                                            \n",
      "2003                 8           0          0.00\n",
      "2004               108           1          0.93\n",
      "2005               300           0          0.00\n",
      "2006               554           0          0.00\n",
      "2007              1142          40          3.50\n",
      "2008              2175         240         11.03\n",
      "2009              4060         704         17.34\n",
      "2010              5255         919         17.49\n",
      "2011              6077         888         14.61\n",
      "2012              6530         854         13.08\n",
      "2013              8638        1273         14.74\n",
      "2014             12139        1262         10.40\n",
      "2015             16468        1644          9.98\n",
      "2016             23596        3001         12.72\n",
      "2017             31922        4672         14.64\n",
      "2018             37991        6122         16.11\n",
      "2019             42442        6577         15.50\n",
      "2020             11268         521          4.62\n",
      "2021              8494        1664         19.59\n",
      "2022             34189         233          0.68\n",
      "2023             55228        1335          2.42\n",
      "2024             57918        2730          4.71\n",
      "2025             22476        1020          4.54\n"
     ]
    }
   ],
   "source": [
    "data[\"year\"] = data[\"date\"].dt.year\n",
    "total_competitors_per_year = data.groupby(data[\"year\"])['personId'].nunique()\n",
    "china_competitors_per_year = data[data['personCountryId'] == 'China'].groupby('year')['personId'].nunique()\n",
    "china_comparison = pd.DataFrame({'TotalCompetitors': total_competitors_per_year, 'ChinaCount': china_competitors_per_year}).fillna(0).astype(int)\n",
    "china_comparison['ChinaPercent'] = (china_comparison['ChinaCount'] / china_comparison['TotalCompetitors'] * 100).round(2)\n",
    "data = data.drop(columns=[\"year\"])\n",
    "print(china_comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39be57e9-d083-491a-adaa-3eee8b9c6aa6",
   "metadata": {},
   "source": [
    "First, we should ignore the percentages for 2020-2023 due to the pandemic shutting down many competitions. However, for 2024 and so far in 2025, the percentages are actually much lower than they have been previously, which is quite surprising considering the amount of top Chinese cubers. Maybe, for some reason, on average cubers in China are just faster than they used to be compared to other countries. To test this hypothesis, I will examine the median solve time in China over time compared to all other countries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "80600ba6-5aee-4414-8dd6-61202b8493d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      NonChinaMedian  ChinaMedian\n",
      "year                             \n",
      "2003           21.48          NaN\n",
      "2004           27.36       25.045\n",
      "2005           25.39          NaN\n",
      "2006           24.34          NaN\n",
      "2007           23.84       24.305\n",
      "2008           21.71       25.660\n",
      "2009           21.28       22.560\n",
      "2010           19.56       19.835\n",
      "2011           18.16       17.720\n",
      "2012           17.55       17.110\n",
      "2013           18.05       16.910\n",
      "2014           18.17       16.290\n",
      "2015           17.86       15.980\n",
      "2016           17.55       16.400\n",
      "2017           16.75       16.190\n",
      "2018           16.16       15.960\n",
      "2019           15.80       15.720\n",
      "2020           15.43       14.740\n",
      "2021           13.89       13.350\n",
      "2022           15.11       13.710\n",
      "2023           15.28       11.790\n",
      "2024           14.60       11.390\n",
      "2025           14.49       11.930\n"
     ]
    }
   ],
   "source": [
    "data[\"year\"] = data[\"date\"].dt.year\n",
    "median_yearly = data[data[\"personCountryId\"] != \"China\"].groupby(data[\"year\"])['time'].median()\n",
    "china_median_yearly = data[data['personCountryId'] == 'China'].groupby('year')['time'].median()\n",
    "china_comparison2 = pd.DataFrame({'NonChinaMedian': median_yearly, 'ChinaMedian': china_median_yearly})\n",
    "data = data.drop(columns=[\"year\"])\n",
    "print(china_comparison2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc09de3b-698e-462b-b09f-38e1a0bfe6d4",
   "metadata": {},
   "source": [
    "Here we can see our hypothesis was correct. Before the pandemic, the median solve time in China was similar to other countries (15.80 vs 15.72) while after the pandemic, the median solve time in China became much faster (14.49 vs 11.93). So what we are seeing in China is a smaller relative population of cubers who are on average much faster than they used to be. Why might this be the case? Well if we examine many top cubers from China, as soon as they started competing, they were already quite fast. Many of them started out already average under 10 seconds, while for many other countries, those competing in their first competition might average 30 seconds. I suspect the culture around cubing in China has grown to be less casual and more competitive. People don't often attend competitions unless they are already very fast, focusing less on the fun of the competition and more on getting results. There might be a much larger overall population of those who can solve a Rubik's cube in China than we would see based on participation in WCA competitions, explaining why there are so many fast cubers from China."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5f0f76-35e4-4824-ada5-b96872993282",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812fae63-16c8-493f-acc2-26c28ddeb951",
   "metadata": {},
   "source": [
    "We answered a number of interesting questions through our analysis. First, we observed that competitors' solves become faster as the average goes on, likely due to them being less nervous. Second, we saw that new competitors have not gotten much faster over time, potentially due to more widespread competitions. Finally, we noted that while the relative population of competitors shrunk in China, their median times became much faster, possibly due to a shift in cubing culture there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f187924-7f2b-4b8b-a928-781d9e303287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
